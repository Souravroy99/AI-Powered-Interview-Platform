
# ğŸš€ AI-Powered Interview Platform

An intelligent, real-time, voice-based interview simulator built with **Next.js**, **Vapi**, **Google Gemini**, and **Firebase**.
This platform allows users to practice interviews using **human-like voice agents**, receive **live feedback**, and get **AI-generated evaluations** with detailed scoring.

Live link:
ğŸ‘‰ [https://ai-powered-interview-platform-new.vercel.app/](https://ai-powered-interview-platform-new.vercel.app/)


---

## ğŸ§  Why This Project?

Traditional mock interview tools rely on text.
This platform is different â€” it provides:

* **Real-time voice conversation**
* **AI-driven dynamic questioning**
* **Gemini-powered reasoning & feedback**
* **Detailed scoring + improvement tips**
* **Full interview transcript & session history**

A fully interactive **AI interviewer** that feels like a real interview.

---

# ğŸŒŸ Features

### ğŸ¤ **Real-Time Voice Interviews**

* Powered by **Vapi Voice Agents**
* STT (Speech â†’ Text)
* TTS (Text â†’ Speech)
* Natural conversational flow

### ğŸ¤– **AI-Powered Interviewer (Google Gemini)**

* Generates contextual follow-up questions
* Evaluates user responses
* Produces structured feedback
* Scores based on multiple criteria
* Provides strengths + improvement areas

### ğŸ“Š **Post-Interview Analytics**

* Total score (0â€“100)
* Category-wise breakdown:

  * Communication
  * Technical Knowledge
  * Problem Solving
  * Cultural Fit
  * Confidence

### ğŸ” **User Authentication**

* Firebase Auth (Email login)

### ğŸ’¾ **Cloud Storage**

* Firestore â†’ saves:

  * Interviews
  * Transcripts
  * Feedback
  * Scores
  * Analytics

### ğŸ–¥ï¸ **Clean UI**

* Built with **Next.js 14**, **Tailwind CSS**, **ShadCN**
* Fully responsive
* Smooth animations via **Framer Motion**

---

# ğŸ›ï¸ Architecture Overview

Below is the full flow of how the system works:

### **1. User speaks into the mic**

Browser â†’ Vapi AI Agent

### **2. Vapi performs Speech-to-Text**

User audio â†’ Text transcript

### **3. Transcript sent to Backend**

Next.js server action receives transcript

### **4. Backend sends prompt to Google Gemini**

Gemini does:

* Question generation
* Conversation logic
* Scoring
* Evaluation

### **5. Gemini returns text response**

Backend â†’ Vapi

### **6. Vapi converts text â†’ speech**

TTS creates natural voice response

### **7. Firebase stores data**

Firestore stores:

* Transcript
* Score
* Feedback
* Session history

---

# âš™ï¸ Tech Stack

## ğŸ¨ Frontend

* **Next.js 14 (App Router)**
* **React**
* **TypeScript**
* **Tailwind CSS**
* **ShadCN UI**
* **React Hook Form + Zod**

## ğŸ§  AI & Voice Layer

* **Google Gemini 2.0 Flash**
* **Vapi.ai Voice Agents**

  * STT (Speech â†’ Text)
  * TTS (Text â†’ Speech)
  * Voice pipeline streaming

## ğŸ”¥ Backend

* **Next.js Server Actions (`"use server"`)**
* **Firebase Admin SDK**
* **AI SDK (`ai` library)**

## ğŸ—„ï¸ Database + Authentication

* **Firebase Firestore**
* **Firebase Auth**
* **Firebase Storage**

## â˜ï¸ Deployment

* **Vercel**

---

# ğŸ—‚ï¸ Project Structure

```
AI-Powered-Interview-Platform/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ (auth)/
â”‚   â”‚   â”œâ”€â”€ layout.tsx
â”‚   â”‚   â””â”€â”€ sign-in/page.tsx
â”‚   â”‚
â”‚   â”œâ”€â”€ (dashboard)/
â”‚   â”‚   â”œâ”€â”€ layout.tsx
â”‚   â”‚   â”œâ”€â”€ dashboard/page.tsx
â”‚   â”‚   â””â”€â”€ previous-interviews/page.tsx
â”‚   â”‚
â”‚   â”œâ”€â”€ (home)/
â”‚   â”‚   â””â”€â”€ page.tsx
â”‚   â”‚
â”‚   â”œâ”€â”€ (interview)/
â”‚   â”‚   â”œâ”€â”€ [id]/page.tsx
â”‚   â”‚   â”œâ”€â”€ layout.tsx
â”‚   â”‚   â””â”€â”€ page.tsx
â”‚   â”‚
â”‚   â”œâ”€â”€ favicon.ico
â”‚   â”œâ”€â”€ globals.css
â”‚   â””â”€â”€ layout.tsx
â”‚
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ charts/
â”‚   â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ interview/
â”‚   â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ Footer.tsx
â”‚   â””â”€â”€ Navbar.tsx
â”‚
â”œâ”€â”€ constants/
â”‚   â”œâ”€â”€ index.ts
â”‚   â””â”€â”€ feedbackSchema.ts
â”‚
â”œâ”€â”€ firebase/
â”‚   â”œâ”€â”€ admin.ts          â† Server-side Firebase Admin SDK
â”‚   â””â”€â”€ config.ts         â† Client-side Firebase config
â”‚
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ auth.ts
â”‚   â”œâ”€â”€ utils.ts
â”‚   â””â”€â”€ stripe.ts (if exists)
â”‚
â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ logo.png
â”‚   â”œâ”€â”€ icons/
â”‚   â””â”€â”€ images/
â”‚
â”œâ”€â”€ types/
â”‚   â”œâ”€â”€ index.ts
â”‚   â””â”€â”€ interview.types.ts
â”‚
â”œâ”€â”€ .env.local.example
â”œâ”€â”€ .eslintrc.json
â”œâ”€â”€ .gitignore
â”œâ”€â”€ next.config.mjs
â”œâ”€â”€ package.json
â”œâ”€â”€ postcss.config.js
â”œâ”€â”€ README.md
â””â”€â”€ tailwind.config.ts
```

* **Server actions** handle AI evaluation & database operations
* **Firebase** stores all interview data
* **Vapi** manages voice agent interactions

---

# ğŸš€ Getting Started

### 1. Clone the repo

```bash
git clone https://github.com/Souravroy99/AI-Powered-Interview-Platform
cd AI-Powered-Interview-Platform
```

### 2. Install dependencies

```bash
npm install
```

### 3. Add environment variables

Create `.env.local`:

```
FIREBASE_PROJECT_ID=
FIREBASE_CLIENT_EMAIL=
FIREBASE_PRIVATE_KEY=
GEMINI_API_KEY=
VAPI_API_KEY=
```

### 4. Run app

```bash
npm run dev
```
